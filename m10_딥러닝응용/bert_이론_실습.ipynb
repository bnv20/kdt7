{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1r4mvC6bLdXWyVdIC0ccxcbFCKGmDeLnv","authorship_tag":"ABX9TyOZugW9WvvM/cHoQX9lch9z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"782a643d8e574aa2ba92f024abe5d0cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5cde3dc8914a4bb1b7fbeeb9a48b3ad6","IPY_MODEL_227c7b3b0818476aac146cb4e6d32df1","IPY_MODEL_2e2604e582f74c779e5bbe81049ae848"],"layout":"IPY_MODEL_5cbc91a00ed64b86b0b4b6ac5af71707"}},"5cde3dc8914a4bb1b7fbeeb9a48b3ad6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_240cc9e4bdc64fe2915628331e2502d9","placeholder":"​","style":"IPY_MODEL_ca820a55581a4bbf8bfd5039c5aeb496","value":"Downloading: 100%"}},"227c7b3b0818476aac146cb4e6d32df1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b20e2b46c5f4f579ba0feb566e76a86","max":371391,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9400c03d2b2949c29d33eef0a20e1ff5","value":371391}},"2e2604e582f74c779e5bbe81049ae848":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c90ff984651442ba1b867191c03df4e","placeholder":"​","style":"IPY_MODEL_7ea6c0cec970443a8976dea58d00a24e","value":" 371k/371k [00:00&lt;00:00, 776kB/s]"}},"5cbc91a00ed64b86b0b4b6ac5af71707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"240cc9e4bdc64fe2915628331e2502d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca820a55581a4bbf8bfd5039c5aeb496":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b20e2b46c5f4f579ba0feb566e76a86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9400c03d2b2949c29d33eef0a20e1ff5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c90ff984651442ba1b867191c03df4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ea6c0cec970443a8976dea58d00a24e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"747b979550ed4fc797f9baab9da3ee31":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6769990485a47e7a075d7a5ae2a6b20","IPY_MODEL_20c7ea125fe84b5ea15bb46f60e6158f","IPY_MODEL_e8b6f3ab00a447d6a72f138131a8f367"],"layout":"IPY_MODEL_218958c73cb14093887d92d829ca5943"}},"f6769990485a47e7a075d7a5ae2a6b20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e9d2f66560446519092c107ff80e83b","placeholder":"​","style":"IPY_MODEL_e87224542b7741448c034045b0ad72b3","value":"Downloading: 100%"}},"20c7ea125fe84b5ea15bb46f60e6158f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb4ea5121d464fc69b1f9b16e290a896","max":77779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_947b5de6697641d5ad5c0fe28fc16f01","value":77779}},"e8b6f3ab00a447d6a72f138131a8f367":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92afdcfb100d4938ba292fb52f2c5537","placeholder":"​","style":"IPY_MODEL_f3574703153943d7964fe75d230e1c51","value":" 77.8k/77.8k [00:00&lt;00:00, 1.51MB/s]"}},"218958c73cb14093887d92d829ca5943":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e9d2f66560446519092c107ff80e83b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e87224542b7741448c034045b0ad72b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb4ea5121d464fc69b1f9b16e290a896":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"947b5de6697641d5ad5c0fe28fc16f01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"92afdcfb100d4938ba292fb52f2c5537":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3574703153943d7964fe75d230e1c51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd5cf3748a9046c78a2e2ad0ead4371f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c1a28aed6a84956bfc8fbd1482119d7","IPY_MODEL_8e1bd876926743168987f76bb67585fb","IPY_MODEL_55f506ba79694656a2afe18041fc25be"],"layout":"IPY_MODEL_c0dc081412054d5bbc6b6beadc7901e3"}},"8c1a28aed6a84956bfc8fbd1482119d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75f6e897b2334662966fdb789248a4af","placeholder":"​","style":"IPY_MODEL_e947447312ef43c495b9d0c4391e9a28","value":"Downloading: 100%"}},"8e1bd876926743168987f76bb67585fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_91bea951c978465fb22463d051124983","max":51,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f7aab80bf8643e98af1a828b4d5ff05","value":51}},"55f506ba79694656a2afe18041fc25be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74dff0c1bed04a25a18d245673c2138c","placeholder":"​","style":"IPY_MODEL_97d2c405b7ee413c9b9d8b58f34514aa","value":" 51.0/51.0 [00:00&lt;00:00, 1.68kB/s]"}},"c0dc081412054d5bbc6b6beadc7901e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75f6e897b2334662966fdb789248a4af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e947447312ef43c495b9d0c4391e9a28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91bea951c978465fb22463d051124983":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f7aab80bf8643e98af1a828b4d5ff05":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74dff0c1bed04a25a18d245673c2138c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97d2c405b7ee413c9b9d8b58f34514aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"575cb9ccecc54dc69cbba9ff7911a779":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3da15a39ddf4451988585f4f2ca5918c","IPY_MODEL_ef34fc58d794451885287a7570cc481a","IPY_MODEL_7cc24c63102849e3b5fabf33c3940d14"],"layout":"IPY_MODEL_f4f9ee28844e46099873b606c60d273a"}},"3da15a39ddf4451988585f4f2ca5918c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9fb2d9f397541d690a963fc250e81ca","placeholder":"​","style":"IPY_MODEL_bcf7160d797f4be88ee6b19bf3b18076","value":"Downloading: 100%"}},"ef34fc58d794451885287a7570cc481a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_11ff38b6e5db448cbcd6eb5c7162d8f6","max":426,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4666685b32354a4bbd9b32bc2a6938d8","value":426}},"7cc24c63102849e3b5fabf33c3940d14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2264763651774e94aecfc8ec5517c281","placeholder":"​","style":"IPY_MODEL_8ede073c150443d08159ffb73f3b410e","value":" 426/426 [00:00&lt;00:00, 13.4kB/s]"}},"f4f9ee28844e46099873b606c60d273a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9fb2d9f397541d690a963fc250e81ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcf7160d797f4be88ee6b19bf3b18076":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11ff38b6e5db448cbcd6eb5c7162d8f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4666685b32354a4bbd9b32bc2a6938d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2264763651774e94aecfc8ec5517c281":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ede073c150443d08159ffb73f3b410e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["- seq2seq\n"," - 시퀀스-투-시퀀스(Sequence-to-Sequence)는 입력된 시퀀스로부터 다른 도메인의 시퀀스를 출력하는 다양한 분야에서 사용되는 모델입니다. 예를 들어 챗봇(Chatbot)과 기계 번역(Machine Translation)이 그러한 대표적인 예인데, 입력 시퀀스와 출력 시퀀스를 각각 질문과 대답으로 구성하면 챗봇으로 만들 수 있고, 입력 시퀀스와 출력 시퀀스를 각각 입력 문장과 번역 문장으로 만들면 번역기로 만들 수 있습니다. 그 외에도 내용 요약(Text Summarization), STT(Speech to Text) 등에서 쓰일 수 있습니다.\n"],"metadata":{"id":"AWyooLYmGw1Q"}},{"cell_type":"markdown","source":["- Attention\n"," - RNN에 기반한 seq2seq 모델에는 크게 두 가지 문제가 있습니다.\n"," - 첫째, 하나의 고정된 크기의 벡터에 모든 정보를 압축하려고 하니까 정보 손실이 발생합니다.\n"," - 둘째, RNN의 고질적인 문제인 기울기 소실(Vanishing Gradient) 문제가 존재합니다.\n","\n"," - 즉, 결국 이는 기계 번역 분야에서 입력 문장이 길면 번역 품질이 떨어지는 현상으로 나타났습니다. 이를 위한 대안으로 입력 시퀀스가 길어지면 출력 시퀀스의 정확도가 떨어지는 것을 보정해주기 위한 등장한 기법인 어텐션(attention)을 활용할 수 있다.\n","\n"," - 어텐션의 기본 아이디어는 디코더에서 출력 단어를 예측하는 매 시점(time step)마다, 인코더에서의 전체 입력 문장을 다시 한 번 참고한다는 점입니다. 단, 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, 해당 시점에서 예측해야할 단어와 연관이 있는 입력 단어 부분을 좀 더 집중(attention)해서 보게 됩니다.\n","\n"," - 어텐션 함수는 주어진 '쿼리(Query)'에 대해서 모든 '키(Key)'와의 유사도를 각각 구합니다. 그리고 구해낸 이 유사도를 가중치로 하여 키와 맵핑되어있는 각각의 '값(Value)'에 반영해줍니다. 그리고 유사도가 반영된 '값(Value)'을 모두 가중합하여 리턴합니다.\n","\n","- 어텐션 중에서는 셀프 어텐션(self-attention)이라는 것이 있습니다. 단지 어텐션을 자기 자신에게 수행한다는 의미입니다. 기존에는 디코더 셀의 은닉 상태가 Q이고 인코더 셀의 은닉 상태가 K라는 점에서 Q와 K가 서로 다른 값을 가지고 있었습니다. 그런데 셀프 어텐션에서는 Q, K, V가 전부 동일합니다.\n","   - Q : 입력 문장의 모든 단어 벡터들\n","   - K : 입력 문장의 모든 단어 벡터들\n","   - V : 입력 문장의 모든 단어 벡터들\n","\n"," -  '그 동물은 길을 건너지 않았다. 왜냐하면 그것은 너무 피곤하였기 때문이다.' 라는 예시에서 그것(it)에 해당하는 것은 과연 길(street)일까요? 동물(animal)일까요? 우리는 피곤한 주체가 동물이라는 것을 아주 쉽게 알 수 있지만 기계는 그렇지 않습니다. 하지만 셀프 어텐션은 입력 문장 내의 단어들끼리 유사도를 구하므로서 그것(it)이 동물(animal)과 연관되었을 확률이 높다는 것을 찾아냅니다.\n","\n"," - Attention이 소스 시퀀스 전체 단어들과 타깃 시퀀스 단어 하나 사이를 연결하는데 쓰이는 반면 셀프 어텐션은 입력 시퀀스 전체 단어들 사이를 연결한다. 이런 Self-Attention을 통해서 각 Input Data들의 유사도를 추정할 수 있다. 만약 'The Animal didn't cross the street, because it was so tired'라는 문장에서 it이 Animal을 가리키는건지 street를 가리키는 것인지 알기 위해, 우리가 독해를 하면서 it이 무엇에서 오는건지 학습하는 것과 비슷한 방식을 거칠 수 있다\n","\n","- Transformer\n"," - 트랜스포머(Transformer)는 2017년 구글이 발표한 논문인 \"Attention is all you need\"에서 나온 모델로 기존의 seq2seq의 구조인 인코더-디코더를 따르면서도, 논문의 이름처럼 어텐션(Attention)만으로 구현한 모델입니다. 이 모델은 RNN을 사용하지 않고, 인코더-디코더 구조를 설계하였음에도 성능도 RNN보다 우수하다는 특징을 갖고있습니다.\n","\n"," - 트랜스포머는 RNN 계열의 seq2seq를 대체하기 위해서 등장했습니다. 그리고 트랜스포머의 인코더는 RNN 인코더를, 트랜스포머의 디코더는 RNN 디코더를 대체할 수 있었습니다.\n","\n"," - 트랜스포머는 RNN을 사용하지 않지만 기존의 seq2seq처럼 인코더에서 입력 시퀀스를 입력받고, 디코더에서 출력 시퀀스를 출력하는 인코더-디코더 구조를 유지하고 있습니다. 다만 다른 점은 인코더와 디코더라는 단위가 N개가 존재할 수 있다는 점입니다.\n","\n"," - 이전 seq2seq 구조에서는 인코더와 디코더에서 각각 하나의 RNN이 t개의 시점(time-step)을 가지는 구조였다면 이번에는 인코더와 디코더라는 단위가 N개로 구성되는 구조입니다. 트랜스포머를 제안한 논문에서는 인코더와 디코더의 개수를 각각 6개를 사용하였습니다.\n","\n","- 트랜스포머는 단어 입력을 순차적으로 받는 방식이 아니므로 단어의 위치 정보를 다른 방식으로 알려줄 필요가 있습니다. 트랜스포머는 단어의 위치 정보를 얻기 위해서 각 단어의 임베딩 벡터에 위치 정보들을 더하여 모델의 입력으로 사용하는데, 이를 포지셔널 인코딩(positional encoding)이라고 합니다.\n","\n"," - 트랜스포머의 인코더는 셀프 어텐션이라는 메커니즘을 통해 문장을 이해합니다. RNN과 그 동작 방식은 다르지만, RNN이 텍스트 분류나 개체명 인식과 같은 다양한 자연어 처리 태스크에 쓰일 수 있다면 트랜스포머의 인코더 또한 가능할 것입니다.\n","실제로 트랜스포머의 인코더는 다양한 분야의 자연어 처리 태스크에서 사용될 수 있었고, 이 아이디어는 후에 배우게 될 BERT라는 모델로 이어지게 됩니다.\n","\n"," - 트랜스포머에서 사용되는 세 가지의 어텐션에 대해서 간단히 정리해봅시다. 첫번째 인코더의 셀프 어텐션은 인코더에서 이루어지지만, 두번째 디코더의 마스크드 셀프 어텐션과 세번째 디코더의 인코더-디코더 어텐션은 디코더에서 이루어집니다. 셀프 어텐션은 본질적으로 Query, Key, Value가 동일한 경우를 말합니다. 반면, 세번째 인코더-디코더 어텐션에서는 Query가 디코더의 벡터인 반면에 Key와 Value가 인코더의 벡터이므로 셀프 어텐션이라고 부르지 않습니다.\n","\n","- 주의할 점은 여기서 Query, Key 등이 같다는 것은 벡터의 값이 같다는 것이 아니라 벡터의 출처가 같다는 의미입니다.\n","정리하면 다음과 같습니다.\n","    - 인코더의 셀프 어텐션 : Query = Key = Value\n","    - 디코더의 마스크드 셀프 어텐션 : Query = Key = Value\n","    - 디코더의 인코더-디코더 어텐션 : Query : 디코더 벡터 / Key = Value : 인코더 벡터\n","\n","  - 세 개의 어텐션에 추가적으로 '멀티 헤드'라는 이름이 붙어있습니다. 이는 트랜스포머가 어텐션을 병렬적으로 수행하는 방법을 의미합니다. \n","\n","https://www.youtube.com/watch?v=Izi9trF3nKY&list=PL7ZVZgsnLwEEoHQAElEPg7l7T6nt25I3N&index=15\n"],"metadata":{"id":"tnNh1WjMH4TJ"}},{"cell_type":"markdown","source":["- BERT\n"," - BERT는 2018년에 공개되어 등장과 동시에 수많은 NLP 태스크에서 최고 성능을 보여주면서 명실공히 NLP의 한 획을 그은 모델로 평가받고 있습니다.\n","\n"," - BERT는 이전 챕터에서 배웠던 트랜스포머를 이용하여 구현되었으며, 위키피디아(25억 단어)와 BooksCorpus(8억 단어)와 같은 레이블이 없는 텍스트 데이터로 사전 훈련된 언어 모델입니다.\n","\n"," - BERT가 높은 성능을 얻을 수 있었던 것은, 레이블이 없는 방대한 데이터로 사전 훈련된 모델을 가지고, 레이블이 있는 다른 작업(Task)에서 추가 훈련과 함께 하이퍼파라미터를 재조정하여 이 모델을 사용하면 성능이 높게 나오는 기존의 사례들을 참고하였기 때문입니다. 다른 작업에 대해서 파라미터 재조정을 위한 추가 훈련 과정을 파인 튜닝(Fine-tuning)이라고 합니다.\n","\n","BERT(Bidirectional Encoder Representations from Transformers)는 2018년에 구글이 공개한 사전 훈련된 모델\n","\n","https://wikidocs.net/115055\n","\n","https://www.youtube.com/watch?v=LEtLfx1dS7Q&list=PL7ZVZgsnLwEEoHQAElEPg7l7T6nt25I3N&index=16\n"],"metadata":{"id":"0tHg88IeLSm0"}},{"cell_type":"markdown","source":["## Input Representation\n","\n","* 3가지의 입력 임베딩(Token, Segment, Position 임베딩)의 합으로 구성\n","\n","![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbABsUL%2FbtqzmTU7OLm%2FYwK6JLhNfTYvxkiFzkfkCK%2Fimg.png)\n"],"metadata":{"id":"sihhpkvbPB11"}},{"cell_type":"markdown","source":["### Token Embeddings\n","\n","* Word Piece 임베딩 방식 사용\n","* 자주 등장하면서 가장 긴 길이의 sub-word를 하나의 단위로 생성\n","* 즉, 자주 등장하는 sub-word은 그 자체가 단위가 되고, 자주 등장하지 않는 단어(rare word)는 sub-word로 쪼개짐\n","* 기존 워드 임베딩 방법은 Out-of-vocabulary (OOV) 문제가 존재하며, 희귀 단어, 이름, 숫자나 단어장에 없는 단어에 대한 학습, 번역에 어려움이 있음\n","* Word Piece 임베딩은 모든 언어에 적용 가능하며, sub-word 단위로 단어를 분절하므로 OOV 처리에 효과적이고 정확도 상승효과도 있음\n","\n","### Sentence Embeddings\n","\n","* BERT는 두 개의 문장을 문장 구분자([SEP])와 함께 결합\n","* 입력 길이의 제한으로 두 문장은 합쳐서 512 subword 이하로 제한\n","* 입력의 길이가 길어질수록 학습시간은 제곱으로 증가하기 때문에 적절한 입력 길이 설정 필요\n","* 한국어는 보통 평균 20 subword로 구성되고 99%가 60 subword를 넘지 않기 때문에 입력 길이를 두 문장이 합쳐 128로 해도 충분\n","* 간혹 긴 문장이 있으므로 우선 입력 길이 128로 제한하고 학습한 후, 128보다 긴 입력들을 모아 마지막에 따로 추가 학습하는 방식을 사용\n","\n","### Position Embedding\n","\n","* BERT는 저자의 이전 논문인 Transformer 모델을 착용\n","* Transformer은 주로 사용하는 CNN, RNN 모델을 사용하지 않고 Self-Attention 모델을 사용\n","* Self-Attention은 입력의 위치에 대해 고려하지 못하므로 입력 토큰의 위치 정보가 필요\n","* Transformer 에서는 Sinusoid 함수를 이용한 Positional encoding을 사용하였고, BERT에서는 이를 변형하여 Position encoding을 사용\n","* Position encoding은 단순하게 Token 순서대로 0, 1, 2, ...와 같이 순서대로 인코딩\n","\n","### 임베딩 취합\n","\n","* BERT는 위에서 소개한 3가지의 입력 임베딩(Token, Segment, Position 임베딩)을 취합하여 하나의 임베딩 값으로 생성\n","* 임베딩의 합에 Layer Normalization과 Dropout을 적용하여 입력으로 사용\n"],"metadata":{"id":"ZWGfJJzDPDY1"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HzeyIMYrPi7d","executionInfo":{"status":"ok","timestamp":1669170936716,"user_tz":-540,"elapsed":10433,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"82c4eac5-6973-4aea-9cff-7aded08d78c6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 13.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 54.6 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n"]}]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JXJCSf7JVxFL","executionInfo":{"status":"ok","timestamp":1669171015242,"user_tz":-540,"elapsed":4300,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"d3fda4a9-ebe4-465d-8924-37a924356963"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 5.3 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"code","source":["!pip install sacremoses"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iUbZvyAyWFwD","executionInfo":{"status":"ok","timestamp":1669171088438,"user_tz":-540,"elapsed":5091,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"458bcfcc-35fc-4278-cba0-26b27804cf83"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2022.6.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.64.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=e09c51c43770695014304088e61b64a6a7a1583ff655c194d8c33f268176a434\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: sacremoses\n","Successfully installed sacremoses-0.0.53\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from transformers import *\n","import json\n","from tqdm import tqdm\n","import os\n","import re\n","import sentencepiece as spm"],"metadata":{"id":"xBQTzQ0aWZzL","executionInfo":{"status":"ok","timestamp":1669171192676,"user_tz":-540,"elapsed":10196,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/e9t/nsmc.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aVWzskFSWvnE","executionInfo":{"status":"ok","timestamp":1669171257192,"user_tz":-540,"elapsed":5753,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"7963689d-14b4-45a0-ad6a-33dc772da45d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'nsmc'...\n","remote: Enumerating objects: 14763, done.\u001b[K\n","remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n","Receiving objects: 100% (14763/14763), 56.19 MiB | 21.83 MiB/s, done.\n","Resolving deltas: 100% (1749/1749), done.\n","Checking out files: 100% (14737/14737), done.\n"]}]},{"cell_type":"code","source":["os.listdir('nsmc')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wFH7kviMXAdb","executionInfo":{"status":"ok","timestamp":1669171292080,"user_tz":-540,"elapsed":239,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"dd4e99e8-b7d6-4acb-e5b9-96f75455d8eb"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['raw',\n"," 'synopses.json',\n"," '.git',\n"," 'ratings_test.txt',\n"," 'ratings.txt',\n"," 'ratings_train.txt',\n"," 'code',\n"," 'README.md']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["train = pd.read_table('nsmc/'+'ratings_train.txt')\n","test = pd.read_table('nsmc/'+'ratings_test.txt')\n","train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"e7Grq7x9XLC7","executionInfo":{"status":"ok","timestamp":1669171365342,"user_tz":-540,"elapsed":1064,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"35e72b62-c632-4cdd-dfc7-7fca94c72026"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"],"text/html":["\n","  <div id=\"df-35d63911-0b4a-457b-b746-d6c5d5b1ad12\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35d63911-0b4a-457b-b746-d6c5d5b1ad12')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-35d63911-0b4a-457b-b746-d6c5d5b1ad12 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-35d63911-0b4a-457b-b746-d6c5d5b1ad12');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_NEzLsDgXgfs","executionInfo":{"status":"ok","timestamp":1669171456125,"user_tz":-540,"elapsed":20321,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"9613bff1-5b87-4156-abf0-c8ac19bcade0"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-6ca858d8-bb34-487a-b71d-b655f9081998\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-6ca858d8-bb34-487a-b71d-b655f9081998\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving tokenization_kobert.py to tokenization_kobert.py\n"]},{"output_type":"execute_result","data":{"text/plain":["{'tokenization_kobert.py': b'# coding=utf-8\\n# Copyright 2018 Google AI, Google Brain and Carnegie Mellon University Authors and the HuggingFace Inc. team and Jangwon Park\\n#\\n# Licensed under the Apache License, Version 2.0 (the \"License\");\\n# you may not use this file except in compliance with the License.\\n# You may obtain a copy of the License at\\n#\\n#     http://www.apache.org/licenses/LICENSE-2.0\\n#\\n# Unless required by applicable law or agreed to in writing, software\\n# distributed under the License is distributed on an \"AS IS\" BASIS,\\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n# See the License for the specific language governing permissions and\\n# limitations under the License.\\n\"\"\" Tokenization classes for KoBert model.\"\"\"\\n\\n\\nimport logging\\nimport os\\nimport unicodedata\\nfrom shutil import copyfile\\n\\nfrom transformers import PreTrainedTokenizer\\n\\n\\nlogger = logging.getLogger(__name__)\\n\\nVOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\\n                     \"vocab_txt\": \"vocab.txt\"}\\n\\nPRETRAINED_VOCAB_FILES_MAP = {\\n    \"vocab_file\": {\\n        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\\n        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\\n        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\\n    },\\n    \"vocab_txt\": {\\n        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\\n        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\\n        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\\n    }\\n}\\n\\nPRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\\n    \"monologg/kobert\": 512,\\n    \"monologg/kobert-lm\": 512,\\n    \"monologg/distilkobert\": 512\\n}\\n\\nPRETRAINED_INIT_CONFIGURATION = {\\n    \"monologg/kobert\": {\"do_lower_case\": False},\\n    \"monologg/kobert-lm\": {\"do_lower_case\": False},\\n    \"monologg/distilkobert\": {\"do_lower_case\": False}\\n}\\n\\nSPIECE_UNDERLINE = u\\'\\xe2\\x96\\x81\\'\\n\\n\\nclass KoBertTokenizer(PreTrainedTokenizer):\\n    \"\"\"\\n        SentencePiece based tokenizer. Peculiarities:\\n            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\\n    \"\"\"\\n    vocab_files_names = VOCAB_FILES_NAMES\\n    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\\n    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\\n    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\\n\\n    def __init__(\\n            self,\\n            vocab_file,\\n            vocab_txt,\\n            do_lower_case=False,\\n            remove_space=True,\\n            keep_accents=False,\\n            unk_token=\"[UNK]\",\\n            sep_token=\"[SEP]\",\\n            pad_token=\"[PAD]\",\\n            cls_token=\"[CLS]\",\\n            mask_token=\"[MASK]\",\\n            **kwargs):\\n        super().__init__(\\n            unk_token=unk_token,\\n            sep_token=sep_token,\\n            pad_token=pad_token,\\n            cls_token=cls_token,\\n            mask_token=mask_token,\\n            **kwargs\\n        )\\n\\n        # Build vocab\\n        self.token2idx = dict()\\n        self.idx2token = []\\n        with open(vocab_txt, \\'r\\', encoding=\\'utf-8\\') as f:\\n            for idx, token in enumerate(f):\\n                token = token.strip()\\n                self.token2idx[token] = idx\\n                self.idx2token.append(token)\\n\\n        try:\\n            import sentencepiece as spm\\n        except ImportError:\\n            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\\n                           \"pip install sentencepiece\")\\n\\n        self.do_lower_case = do_lower_case\\n        self.remove_space = remove_space\\n        self.keep_accents = keep_accents\\n        self.vocab_file = vocab_file\\n        self.vocab_txt = vocab_txt\\n\\n        self.sp_model = spm.SentencePieceProcessor()\\n        self.sp_model.Load(vocab_file)\\n\\n    @property\\n    def vocab_size(self):\\n        return len(self.idx2token)\\n\\n    def get_vocab(self):\\n        return dict(self.token2idx, **self.added_tokens_encoder)\\n\\n    def __getstate__(self):\\n        state = self.__dict__.copy()\\n        state[\"sp_model\"] = None\\n        return state\\n\\n    def __setstate__(self, d):\\n        self.__dict__ = d\\n        try:\\n            import sentencepiece as spm\\n        except ImportError:\\n            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\\n                           \"pip install sentencepiece\")\\n        self.sp_model = spm.SentencePieceProcessor()\\n        self.sp_model.Load(self.vocab_file)\\n\\n    def preprocess_text(self, inputs):\\n        if self.remove_space:\\n            outputs = \" \".join(inputs.strip().split())\\n        else:\\n            outputs = inputs\\n        outputs = outputs.replace(\"``\", \\'\"\\').replace(\"\\'\\'\", \\'\"\\')\\n\\n        if not self.keep_accents:\\n            outputs = unicodedata.normalize(\\'NFKD\\', outputs)\\n            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\\n        if self.do_lower_case:\\n            outputs = outputs.lower()\\n\\n        return outputs\\n\\n    def _tokenize(self, text, return_unicode=True, sample=False):\\n        \"\"\" Tokenize a string. \"\"\"\\n        text = self.preprocess_text(text)\\n\\n        if not sample:\\n            pieces = self.sp_model.EncodeAsPieces(text)\\n        else:\\n            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\\n        new_pieces = []\\n        for piece in pieces:\\n            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\\n                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\\n                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\\n                    if len(cur_pieces[0]) == 1:\\n                        cur_pieces = cur_pieces[1:]\\n                    else:\\n                        cur_pieces[0] = cur_pieces[0][1:]\\n                cur_pieces.append(piece[-1])\\n                new_pieces.extend(cur_pieces)\\n            else:\\n                new_pieces.append(piece)\\n\\n        return new_pieces\\n\\n    def _convert_token_to_id(self, token):\\n        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\\n        return self.token2idx.get(token, self.token2idx[self.unk_token])\\n\\n    def _convert_id_to_token(self, index, return_unicode=True):\\n        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\\n        return self.idx2token[index]\\n\\n    def convert_tokens_to_string(self, tokens):\\n        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\\n        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\\n        return out_string\\n\\n    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\\n        \"\"\"\\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\\n        by concatenating and adding special tokens.\\n        A KoBERT sequence has the following format:\\n            single sequence: [CLS] X [SEP]\\n            pair of sequences: [CLS] A [SEP] B [SEP]\\n        \"\"\"\\n        if token_ids_1 is None:\\n            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\\n        cls = [self.cls_token_id]\\n        sep = [self.sep_token_id]\\n        return cls + token_ids_0 + sep + token_ids_1 + sep\\n\\n    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\\n        \"\"\"\\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\\n        Args:\\n            token_ids_0: list of ids (must not contain special tokens)\\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\\n                for sequence pairs\\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\\n                special tokens for the model\\n        Returns:\\n            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\\n        \"\"\"\\n\\n        if already_has_special_tokens:\\n            if token_ids_1 is not None:\\n                raise ValueError(\\n                    \"You should not supply a second sequence if the provided sequence of \"\\n                    \"ids is already formated with special tokens for the model.\"\\n                )\\n            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\\n\\n        if token_ids_1 is not None:\\n            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\\n        return [1] + ([0] * len(token_ids_0)) + [1]\\n\\n    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\\n        \"\"\"\\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\\n        A KoBERT sequence pair mask has the following format:\\n        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\\n        | first sequence    | second sequence\\n        if token_ids_1 is None, only returns the first portion of the mask (0\\'s).\\n        \"\"\"\\n        sep = [self.sep_token_id]\\n        cls = [self.cls_token_id]\\n        if token_ids_1 is None:\\n            return len(cls + token_ids_0 + sep) * [0]\\n        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\\n\\n    def save_vocabulary(self, save_directory):\\n        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\\n            to a directory.\\n        \"\"\"\\n        if not os.path.isdir(save_directory):\\n            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\\n            return\\n\\n        # 1. Save sentencepiece model\\n        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\\n\\n        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\\n            copyfile(self.vocab_file, out_vocab_model)\\n\\n        # 2. Save vocab.txt\\n        index = 0\\n        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\\n        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\\n            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\\n                if index != token_index:\\n                    logger.warning(\\n                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\\n                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\\n                    )\\n                    index = token_index\\n                writer.write(token + \"\\\\n\")\\n                index += 1\\n\\n        return out_vocab_model, out_vocab_txt\\n'}"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eAjHQcwtX0Xt","executionInfo":{"status":"ok","timestamp":1669171482307,"user_tz":-540,"elapsed":253,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"46294353-1fe1-4a3b-b3b4-5e158c2e8884"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["drive  nsmc  sample_data  tokenization_kobert.py\n"]}]},{"cell_type":"code","source":["from tokenization_kobert import KoBertTokenizer\n","tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":823,"referenced_widgets":["782a643d8e574aa2ba92f024abe5d0cf","5cde3dc8914a4bb1b7fbeeb9a48b3ad6","227c7b3b0818476aac146cb4e6d32df1","2e2604e582f74c779e5bbe81049ae848","5cbc91a00ed64b86b0b4b6ac5af71707","240cc9e4bdc64fe2915628331e2502d9","ca820a55581a4bbf8bfd5039c5aeb496","2b20e2b46c5f4f579ba0feb566e76a86","9400c03d2b2949c29d33eef0a20e1ff5","4c90ff984651442ba1b867191c03df4e","7ea6c0cec970443a8976dea58d00a24e","747b979550ed4fc797f9baab9da3ee31","f6769990485a47e7a075d7a5ae2a6b20","20c7ea125fe84b5ea15bb46f60e6158f","e8b6f3ab00a447d6a72f138131a8f367","218958c73cb14093887d92d829ca5943","8e9d2f66560446519092c107ff80e83b","e87224542b7741448c034045b0ad72b3","cb4ea5121d464fc69b1f9b16e290a896","947b5de6697641d5ad5c0fe28fc16f01","92afdcfb100d4938ba292fb52f2c5537","f3574703153943d7964fe75d230e1c51","fd5cf3748a9046c78a2e2ad0ead4371f","8c1a28aed6a84956bfc8fbd1482119d7","8e1bd876926743168987f76bb67585fb","55f506ba79694656a2afe18041fc25be","c0dc081412054d5bbc6b6beadc7901e3","75f6e897b2334662966fdb789248a4af","e947447312ef43c495b9d0c4391e9a28","91bea951c978465fb22463d051124983","4f7aab80bf8643e98af1a828b4d5ff05","74dff0c1bed04a25a18d245673c2138c","97d2c405b7ee413c9b9d8b58f34514aa","575cb9ccecc54dc69cbba9ff7911a779","3da15a39ddf4451988585f4f2ca5918c","ef34fc58d794451885287a7570cc481a","7cc24c63102849e3b5fabf33c3940d14","f4f9ee28844e46099873b606c60d273a","b9fb2d9f397541d690a963fc250e81ca","bcf7160d797f4be88ee6b19bf3b18076","11ff38b6e5db448cbcd6eb5c7162d8f6","4666685b32354a4bbd9b32bc2a6938d8","2264763651774e94aecfc8ec5517c281","8ede073c150443d08159ffb73f3b410e"]},"id":"QqM_ugl5X4w2","executionInfo":{"status":"ok","timestamp":1669171611121,"user_tz":-540,"elapsed":2088,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"a38ff201-9942-4a80-ee17-fadfda22b7c4"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/371k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"782a643d8e574aa2ba92f024abe5d0cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"747b979550ed4fc797f9baab9da3ee31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd5cf3748a9046c78a2e2ad0ead4371f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading file tokenizer_78b3253a26.model from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/8ebf2818cfd85570737d31ed8cd7aaa000e7056c/tokenizer_78b3253a26.model\n","loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/8ebf2818cfd85570737d31ed8cd7aaa000e7056c/vocab.txt\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/8ebf2818cfd85570737d31ed8cd7aaa000e7056c/tokenizer_config.json\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/426 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"575cb9ccecc54dc69cbba9ff7911a779"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/8ebf2818cfd85570737d31ed8cd7aaa000e7056c/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"monologg/kobert\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 8002\n","}\n","\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n","The class this function is called from is 'KoBertTokenizer'.\n"]}]},{"cell_type":"code","source":["def convert_data(data_df):\n","  global tokenizer\n","  SEQ_LEN = 64\n","\n","  tokens, masks, segments, targets = [],[],[],[]\n","\n","  for i in tqdm(range(len(data_df))):\n","    token = tokenizer.encode(data_df[DATA_COLUMN][i], truncation=True, padding='max_length', max_length=SEQ_LEN)\n","    num_zeros = token.count(0)\n","    mask = [1] * (SEQ_LEN-num_zeros) + [0] * num_zeros\n","    segment = [0] * SEQ_LEN\n","\n","    tokens.append(token)\n","    masks.append(mask)\n","    segments.append(segment)\n","\n","    targets.append(data_df[LABEL_COLUMN][i])\n","\n","  tokens = np.array(tokens)\n","  masks = np.array(masks)\n","  segments = np.array(segments)\n","  targets = np.array(targets)\n","\n","  return [tokens, masks, segments], targets"],"metadata":{"id":"tcaGGpOSYXw-","executionInfo":{"status":"ok","timestamp":1669172948156,"user_tz":-540,"elapsed":285,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def load_data(pandas_dataframe):\n","  data_df = pandas_dataframe\n","  data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n","  data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\n","  data_x, data_y = convert_data(data_df)\n","\n","  return data_x, data_y\n","\n","SEQ_LEN = 64\n","BATCH_SIZE = 32\n","DATA_COLUMN = 'document'\n","LABEL_COLUMN = 'label'\n","\n","train_x,train_y = load_data(train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ettEuTikdeoI","executionInfo":{"status":"ok","timestamp":1669173313048,"user_tz":-540,"elapsed":32994,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"d8ac18e3-02a9-48f3-d4b1-6f60744686b7"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 150000/150000 [00:30<00:00, 4885.85it/s]\n"]}]},{"cell_type":"code","source":["test_x, test_y = load_data(test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zckkK7gfeRnH","executionInfo":{"status":"ok","timestamp":1669173326405,"user_tz":-540,"elapsed":11091,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"872a2562-e019-472d-8203-b78eeb690ff7"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 50000/50000 [00:10<00:00, 4831.27it/s]\n"]}]},{"cell_type":"code","source":["# 버트를 활용한 감성분석 모델 생성\n","\n","model = TFBertModel.from_pretrained('monologg/kobert', from_pt=True)\n","token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n","mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n","segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n","bert_output = model([token_inputs, mask_inputs,segment_inputs])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AdUoSPe6e7-X","executionInfo":{"status":"ok","timestamp":1669173732615,"user_tz":-540,"elapsed":6699,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"31d252f7-4421-4b22-d782-24a35edae39c"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/8ebf2818cfd85570737d31ed8cd7aaa000e7056c/config.json\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.24.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 8002\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/8ebf2818cfd85570737d31ed8cd7aaa000e7056c/pytorch_model.bin\n","Loading PyTorch weights from /root/.cache/huggingface/hub/models--monologg--kobert/snapshots/8ebf2818cfd85570737d31ed8cd7aaa000e7056c/pytorch_model.bin\n","PyTorch checkpoint contains 92,186,880 parameters\n","Loaded 92,186,880 parameters in the TF 2.0 model.\n","All PyTorch model weights were used when initializing TFBertModel.\n","\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}]},{"cell_type":"code","source":["bert_output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6FXd-TNNgQ1P","executionInfo":{"status":"ok","timestamp":1669173802354,"user_tz":-540,"elapsed":293,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"74aa0d5c-6f18-47ea-ce2c-6a73d9f21e58"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<KerasTensor: shape=(None, 64, 768) dtype=float32 (created by layer 'tf_bert_model_1')>, pooler_output=<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_bert_model_1')>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["bert_output = bert_output[1] \n","bert_output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JM2-GelOjp12","executionInfo":{"status":"ok","timestamp":1669174594294,"user_tz":-540,"elapsed":257,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"e748119f-141a-4832-f4e5-426064d942eb"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([None, 768])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# optimizer\n","\n","!pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDuTlU0OgzCO","executionInfo":{"status":"ok","timestamp":1669174603407,"user_tz":-540,"elapsed":3512,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"90285844-11dd-48ac-c414-d26f100d9edb"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.18.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n"]}]},{"cell_type":"code","source":["import tensorflow_addons as tfa \n","\n","opt = tfa.optimizers.RectifiedAdam(lr=1.0e-5, weight_decay=0.0025, warmup_proportion=0.1)\n","# opt = tfa.optimizers.RectifiedAdam(lr=5.0e-5, total_steps=2344*2, warmup_proportion=0.1, min_lr=1e-5, clipnorm=1.0)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z1JDGIyPg-EN","executionInfo":{"status":"ok","timestamp":1669174605243,"user_tz":-540,"elapsed":402,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"0cdb48d8-d564-4f60-8b5e-0bb62bb10315"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow_addons/optimizers/rectified_adam.py:121: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["sentiment_drop = tf.keras.layers.Dropout(0.5)(bert_output)\n","sentiment_first = tf.keras.layers.Dense(1,activation='sigmoid',kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(sentiment_drop)\n","sentiment_model = tf.keras.Model([token_inputs, mask_inputs,segment_inputs],sentiment_first)\n","sentiment_model.compile(optimizer = opt, loss=tf.keras.losses.BinaryCrossentropy(),metrics=['accuracy'])"],"metadata":{"id":"OFVXUiqaho8O","executionInfo":{"status":"ok","timestamp":1669174608603,"user_tz":-540,"elapsed":374,"user":{"displayName":"kevin park","userId":"02703084888761299921"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["sentiment_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EvjM4aggip52","executionInfo":{"status":"ok","timestamp":1669174705936,"user_tz":-540,"elapsed":246,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"575cfcbf-574e-4728-f2ae-72590231a1df"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_word_ids (InputLayer)    [(None, 64)]         0           []                               \n","                                                                                                  \n"," input_masks (InputLayer)       [(None, 64)]         0           []                               \n","                                                                                                  \n"," input_segment (InputLayer)     [(None, 64)]         0           []                               \n","                                                                                                  \n"," tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  92186880    ['input_word_ids[0][0]',         \n","                                thPoolingAndCrossAt               'input_masks[0][0]',            \n","                                tentions(last_hidde               'input_segment[0][0]']          \n","                                n_state=(None, 64,                                                \n","                                768),                                                             \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," dropout_76 (Dropout)           (None, 768)          0           ['tf_bert_model_1[0][1]']        \n","                                                                                                  \n"," dense (Dense)                  (None, 1)            769         ['dropout_76[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 92,187,649\n","Trainable params: 92,187,649\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["sentiment_model.fit(train_x,train_y,epochs=2,shuffle=True, batch_size=64,validation_data=(test_x,test_y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sFfq9623kKA3","executionInfo":{"status":"ok","timestamp":1669179100794,"user_tz":-540,"elapsed":4307744,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"7c524cc0-ae91-45d6-e254-056e5b270677"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2344/2344 [==============================] - 2151s 907ms/step - loss: 0.4075 - accuracy: 0.7986 - val_loss: 0.2919 - val_accuracy: 0.8768\n","Epoch 2/2\n","2344/2344 [==============================] - 2125s 907ms/step - loss: 0.2695 - accuracy: 0.8885 - val_loss: 0.2780 - val_accuracy: 0.8894\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fbfd57f9e50>"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["sentiment_model.evaluate(test_x,test_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5PHjxuLukhG2","executionInfo":{"status":"ok","timestamp":1669179657656,"user_tz":-540,"elapsed":262301,"user":{"displayName":"kevin park","userId":"02703084888761299921"}},"outputId":"ef53e379-a28d-404f-e6f8-7d178c1c3323"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["1563/1563 [==============================] - 212s 136ms/step - loss: 0.2780 - accuracy: 0.8894\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.27796950936317444, 0.8894000053405762]"]},"metadata":{},"execution_count":34}]}]}